---
title: "Estimating the proportion of cases that are reported during an outbreak"
output:
  bookdown::html_vignette2:
    fig_caption: yes
    code_folding: show
pkgdown:
  as_is: true
bibliography: resources/library.json
link-citations: true
vignette: >
  %\VignetteIndexEntry{Estimating the proportion of cases that are reported during an outbreak}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dpi = 300,
  fig.width = 5, fig.height = 3
)
```

Cases, infections or hospitalisations and deaths might be under-ascertained during an outbreak of an infectious disease for reasons including testing capacity, criteria not being sufficient to identify all infections, or symptom-based testing rather than random sampling, or changes in case definition over time.

::: {.alert .alert-warning}
New to calculating disease severity using _cfr_? You might want to see the ["Get started" vignette first](cfr.html).
:::

::: {.alert .alert-primary}
## Use case {-}

We wish to estimate one of the typical severity quantities used in epidemiology -- the *case fatality risk (CFR)*, *infection hospitality risk (IFR)* or  *hospitalisation fatality risk (HFR)* -- using a method that uses a time series of cases, infections or hospitalisations (respectively) and deaths, _while correcting for the delay in reporting the outcomes of cases_.
:::

::: {.alert .alert-secondary}
## What we have {-}

* A time-series of cases, hospitalisations or some other proxy for infections over time;
* A time-series of deaths;
* A delay distribution, describing the probability an individual will die $t$ days after they were initially infected.
:::

<!-- This can lead to biases due to some infections either being asymptomatic or having a pre-symptomatic phase.

For example, during the recent COVID-19 pandemic, the U.K. did not roll out widespread testing until around May 2020.
This means that during March and April, infections were heavily under-ascertained.
We focus on this period within this vignette, as it illustrates the use for this analysis pipeline well. -->

This vignette shows how to use the `estimate_reporting()` function in _cfr_ to estimate the proportion of cases, infections or hospitalisations ascertained, and consequently, the extent of under-ascertainment or under-reporting.

First load _cfr_ and packages to access and plot data.

```{r, message = FALSE, warning=FALSE, eval = TRUE}
# load {cfr} and data packages
library(cfr)
library(epiparameter)
library(covidregionaldata)

# packages to wrangle and plot data
library(dplyr)
library(tidyr)
library(purrr)
library(scales)
library(forcats)
library(ggplot2)
```

## Ascertainment for the Covid-19 pandemic in the U.K.

The function `estimate_reporting()` from the _cfr_ package estimates the proportion of cases, infections, hospitalisations -- or whichever proxy for infections is provided -- which have been ascertained.

<!-- The method used within this function extends the methods outlined in the previous vignettes about estimating the severity during an ongoing outbreak and measuring how the severity changes over time. -->

The methods are based on the @nishiura2009 to estimate severity, and are extended by combining the resulting severity estimates with an assumed baseline severity estimate.

The proportion of cases, infections or other quantity provided that have been ascertained is given by the ratio of the (assumed) true baseline severity estimate, to the delay-adjusted severity estimate.

The delay-adjusted severity estimates can be calculated using either the `estimate_static()` or the `estimate_time_varying()` functions. 

<!-- # Example with data from the ongoing COVID-19 pandemic in the U.K.

We outline how the time-varying severity estimation works in *cfr* using a number of examples.
The data for all of the examples is from the ongoing COVID-19 epidemic.
Firstly, we analyse the U.K. data, then we pick three other countries with large outbreaks to analyse. -->

### Preparing the raw data

First we subset the data so that we focus on just the first few months of the COVID-19 outbreak in the U.K.
During this period test availability changed dramatically as a result of the vaccine campaign.

We download the data from the [_covidregionaldata_ package](https://github.com/epiforecasts/covidregionaldata).

```{r}
# get Covid data from {covidregionaldata}
df_covid_uk <- get_national_data(
  countries = "united kingdom", source = "who", verbose = FALSE
)

# rename columns wth {dplyr}
df_covid_uk <- rename(df_covid_uk, cases = cases_new, deaths = deaths_new)
```

We then subset the data to focus on just the first few months of the outbreak.

```{r}
# the first few months of the pandemic
df_covid_uk_subset <- filter(df_covid_uk, date <= "2020-05-31")
```

Then, we plot case incidence data with following command.
Further plotting commands are hidden for brevity.

```{r fig.cap="Incidence of cases over time for the ongoing COVID-19 outbreak in the U.K.", class.source = 'fold-hide'}
ggplot(df_covid_uk_subset) +
  geom_step(
    aes(
      x = date, y = cases
    ),
    colour = "darkblue"
  ) +
  scale_x_date(
    date_labels = "%b-%Y"
  ) +
  scale_y_continuous(
    labels = comma
  ) +
  labs(
    x = "Date", y = "Cases"
  )
```

Then, we plot the death incidence data with following command:

```{r fig.cap="Incidence of deaths over time for the ongoing COVID-19 outbreak in the U.K.", class.source = 'fold-hide'}
ggplot(df_covid_uk_subset) +
  geom_step(
    aes(
      x = date, y = deaths
    ),
    colour = "darkred"
  ) +
  scale_x_date(
    date_labels = "%b-%Y"
  ) +
  scale_y_continuous(
    labels = comma
  ) +
  labs(
    x = "Date", y = "Deaths"
  )
```

### Onset-to-death distribution for Covid-19

We retrieve the appropriate distribution reported in @linton2020 using the `epidist_db()` function from the [_epiparameter_ package](https://epiverse-trace.github.io/epiparameter/).

```{r}
onset_to_death_covid <- epidist_db(
  disease = "COVID-19",
  epi_dist = "onset_to_death",
  author = "Linton_etal"
)
```

### Estimating the proportion of cases that have been ascertained

We use the `estimate_reporting()` function within the _cfr_ package to calculate the time-varying CFR for the COVID-19 epidemic in the U.K.

The function includes a `type` argument, which determines whether `estimate_static()` or `estimate_time_varying()` is used to estimate the delay-adjusted severity of the disease.

The `severity_baseline` argument in the `estimate_reporting()` determines the denominator in the resulting under-ascertainment calculation.
We assume that the 'true' CFR of Covid-19 is 0.014.

The other arguments are the same as those found in the `estimate_time_varying()`. 

```{r }
df_reporting_static <- estimate_reporting(
  data = df_covid_uk_subset,
  epi_dist = onset_to_death_covid,
  type = "static",
  severity_baseline = 0.014,
  correct_for_delays = TRUE
)
```

```{r }
df_reporting_varying <- estimate_reporting(
  data = df_covid_uk,
  epi_dist = onset_to_death_covid,
  type = "varying",
  severity_baseline = 0.014,
  smooth_inputs = TRUE,
  burn_in_value = 7,
  correct_for_delays = TRUE,
  max_date = "2020-06-30"
)
```

Once we have calculated both severity quantities over time, we visualise the results.

```{r}
# the static reporting estimate
df_reporting_static

# the time-varying reporting estimate
df_reporting_varying
```

## Ascertainment in countries with large early COVID-19 outbreaks

Finally, we estimate ascertainment for all countries with large early outbreaks of Covid-19.

We define a large outbreak as one which has caused at least 100,000 deaths, and focus on the period between the start of each outbreak to the 1st June 2020.

We do so as it was this period where under-ascertainment of cases and infections was likely the highest, as tests were still being developed and had not been made widely available in many countries.


```{r}
df_covid <- get_national_data(
  source = "who", verbose = FALSE
) %>%
  rename(cases = cases_new, deaths = deaths_new)

df_covid_subset <- filter(df_covid, date <= "2020-05-31")
```

We adopt a data science approach to apply the `estimate_reporting()` function across data grouped by country.
We refer the user to the book [R for Data Science](https://r4ds.had.co.nz/) for a better explanation of some of the code used here, including from the packages in [the Tidyverse](https://www.tidyverse.org/).


```{r}
# calculate the total number deaths by country and filter for countries
# with 100,000 deaths, and then filter for the first six months of 2020
df_reporting <- df_covid %>%
  group_by(iso_code) %>%
  mutate(total_deaths = max(deaths_total)) %>%
  filter(total_deaths > 100000 & !is.na(country)) %>%
  filter(date < "2020-06-01") %>%
  ungroup()

# nest the data
df_reporting <- nest(df_reporting, .by = country)

# calculate the reporting rate in each country using
# map on nested dataframes
df_reporting <- mutate(
  df_reporting,
  reporting = map(
    .x = data, .f = estimate_reporting,
    # arguments to function
    epi_dist = onset_to_death_covid, type = "varying",
    burn_in_value = 7, smooth_inputs = TRUE, correct_for_delays = TRUE
  )
)

# unnest the data
df_reporting <- unnest(df_reporting, cols = "reporting")

# visualise the data
head(df_reporting)
```

Plot the ascertainment for each country.

```{r fig.cap = "Example plot of the ascertainment rate by country during the early stages of the Covid-19 pandemic.", class.source = 'fold-hide'}
df_reporting %>%
  ggplot() +
  geom_pointrange(
    aes(
      x = fct_reorder(country, reporting_me),
      y = reporting_me,
      ymin = reporting_lo,
      ymax = reporting_hi
    )
  ) +
  coord_flip() +
  labs(x = NULL, y = "Ascertainment Rate") +
  theme(legend.position = "none") +
  scale_y_continuous(
    labels = percent, limits = c(0, 1)
  )
```

## References
